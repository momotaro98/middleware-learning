---
marp: true
---

# Chapter 5

レプリケーション

-----

レプリケーションを行う理由

* データを地理的に近くに置き、レイテンシを下げるため
* 一部に障害があっても動作しつづけるよう、可用性を上げるため
* 読み取りのクエリを処理するマシン数をスケールアウトし、スループットを高めるため

-----

## 5.1 リーダー(Leader)とフォロワー(Follower)

シングルLeader

1. 1つのLeader(マスター、プライマリ)があり、DBへ書き込みしたい場合はLeaderに送信しなければいけない。
2. 他のレプリカはFollowerと呼ばれる。Leaderは新しいデータをローカルストレージに書き込むと、その変更データをレプリケーションログあるいは変更ストリームとしてすべてのFollowerに送信する。
3. クライアントがDBから読み取りをしたい場合はリーダーあるいはいずれかのFollowerにクエリを送ることができる。

-----

### 5.1.1 同期と非同期のレプリケーション

* 同期型のレプリケーションのデメリット(非同期のメリット)
  * 1つでもFollowerが反応を返さなかったとき、書き込み処理ができなくなること。
* 非同期のデメリット(同期のメリット)
  * Leaderとの一貫性が保証されていない

------

### 5.1.2 新しいFollowerのセットアップ

新しいFollowerがLeaderのデータの正確なコピーを持っていることはどのように保証できるか。

フォロワーのセットアップは整合性を保ちながらダウンタイム無しに行える。概念的には以下の手順になる。

---

1. どこかの時点でLeaderから一貫性のあるスナップショットを取る。
2. 取得したスナップショットを、新しいFollowerのノードにコピーする。

---

3. FollowerはLeaderに接続し、スナップショットが取得された後に生じたすべてのデータ変更を要求する。そのためには,スナップショットがLeaderのレプリケーションログのどの時点のものなのかを示す正確な位置が必要になる。この位置はたとえばPostgreSQLならば**ログシーケンス番号**、MySQLでは**binlog coordinates**といったように、様々な名前で呼ばれる。

4. Followerがスナップショット取得以降のデータ変更のバックログを処理し終えたら、それは**Catch Up**したと言える。これ以降、そのFollowerは、Leaderからのデータ変更を、発生ごとに処理していける。
  
-----

### 5.1.3 ノード障害への対応

-----

#### 5.1.3.2 Leaderの障害 : Failover

フェイルオーバーではFollowerのいずれかをLeaderに昇格させ、クライアントは書き込み先を新しいLeaderに設定し、他のFollowerはデータ更新を新しいLeaderから受信しはじめる必要がある。

---

自動的なフェイルオーバーの流れ

1. Leaderに障害が起きたことの確認。
  * たとえば30秒間反応を返さなければそのノードを落ちているとみなす。
2. 新しいLeaderの選出
  * 選出(合意)のプロセスか**コントローラーノード**によって指定される。
3. 新しいLeaderを使用するためのシステムの再設定

---

フェイルオーバーには、問題になることが多くある。

* 新しいLeaderは前Leaderのデータをすべて持っていない可能性がある。
* 2つのノードが共に自身をLeaderだと信じてしまうことがある。これは**スプリットブレイン**と呼ばれる。
  * どちらのLeaderも書き込みを受け付けるので衝突回避ができずデータが損失する危険がある。
* 何秒待てば落ちているとみなして良いのか。

上記の課題があるため、運用チームによってはフェイルオーバーは手動を好む場合もある。

-----

### 5.1.4 レプリケーションログの実装

---

#### 5.1.4.1 ステートメントベースのレプリケーション

INSERT、UPDATE、DELETE文がそのままFollowerに転送される。

この手法の欠点は、`INSERT INTO ... value(now())` のような実行環境依存の非決定な関数(now(), rand())に対処ができない。

---

#### 5.1.4.2 Write-Ahead Log (WAL) の転送

Chapter3でのlog-structuredストレージエンジン、Bツリーでのwrite-aheadlogをそのままFollowerに転送する。

この手法の欠点は、ログはディスクブロッグの位置を含むデータで非常に低レベルであり、LeaderとFollowerでストレージフォーマットに違いが生じると動作することができなくなってしまう。

---

#### 5.1.4.3 論理(行ベース)ログレプリケーション

レプリケーションやストレージエンジン用に独立したログのフォーマットを使うという手法がある。これはストレージエンジンの内部から分離される。そのため、後方互換性を保ちやすくなっている。

**MySQLのbinlog**は行ベースのレプリケーションを利用するよう設定された場合、このアプローチを採用している。

---

#### 5.1.4.4 トリガベースレプリケーション

通常、トリガベースレプリケーションは他のレプリケーションと比べてオーバーヘッドが大きく、バグが生じやすく、データベースに組み込まれているレプリケーションよりも制約が生じやすくなる。

-----

## 5.2 レプリケーションラグにまつわる問題

概念

* 自分が書いた内容の読み取りにはデータ更新順序の不整合がでないようにする
* 誰かが連続して行った複数の読み取りにおいて、時間が巻き戻らないようにする (**モノトニックな読み取り**)
* チャットなどの書き込みの順序が入れ替わらないようにする (**一貫性のあるプレフィックス読み取り**)

-----

## 5.3 Multi-Leaderレプリケーション

### 5.3.1 いつMulti-Leaderレプリケーションを採用するのか(ユースケース)

#### 5.3.1.1 マルチデータセンターでの運用でMulti-Leaderレプリケーションを使う

Multi-Leaderの利点

* パフォーマンス
* データセンターの障害に対する耐性
* ネットワークの問題に対する耐性

---

Multi-Leaderの大きな欠点

書き込みの衝突の回避・解決という難しい問題が生じること

また、Multi-Leaderレプリケーションは、自動インクリメント、トリガー、整合性制約など、データベースの他の機能と悪い相互作用を引き起こすことがある。

そのため、Multi-Leaderレプリケーションは可能であれば避けるべき危険領域とみなされる。

---

#### 5.3.1.2 Webサービスでのオフライン上のデバイスがある意味Multi-Leaderレプリケーションになる。

PC、スマホなどすべてのデバイスはLeaderのように振る舞い、ローカルデータベースを持つ。レプリケーションラグはインターネットにつながるまで、とみなすことができる。

---

#### 5.3.1.3 Collaborativeな編集

**リアルタイムCollaborative編集**アプリケーションでは複数のユーザーがドキュメントを同時編集できる。Google Docs、Confluence、Cacoo。

編集の衝突がないことを保証したいならば、アプリはドキュメント変更箇所のロックを取る必要がある。この場合は、Leader上でトランザクションを扱うシングルLeaderレプリケーションと等価である。

ロックを回避し、素早いコラボレーションを提供したい場合は、衝突解決のようなMulti-Leaderレプリケーションのあらゆる問題が持ち込まれることになる。

-----

### 5.3.2 書き込み衝突の処理

---

#### 5.3.2.3 一貫した状態への収束(convergent)

収束的な衝突の解決方法

* **最後の書き込みを勝たせる(last write wins, LWW)**という手法がある。←広く採用されているがデータ損失の危険がある。
* 何らかの方法でマージする。
* 衝突を記録し、後のどこかで衝突解決するようなアプリケーションを書く。(おそらくそれはユーザーに確認を求めることになる)

---

#### 5.3.2.4 カスタム衝突解決ロジック

多くのMulti-Leaderレプリケーションツールでは、衝突解決ロジックをアプリケーションのコードで書けるようになっている。

-----

### 5.3.3 Multi-Leaderレプリケーションのトポロジー

* all-to-all型
* 循環型
* スター型

-----

## 5.4 Leaderレスレプリケーション

Amazonが独自のDynamoシステムを開発したのをきっかけにLeaderレスレプリケーションは流行りのデータベースアーキテクチャになった。

Leaderレスの設計はDBの利用方法に大きな違いをもたらす。

この種のデータベースは**Dynamoスタイル**とも呼ばれる。

-----

### 5.4.1 ノードがダウンしている状態でのデータベースへの書き込み

Leaderレス構成ではクライアントは複数のノードらに同時に書き込みをする。

TODO: 図を貼る。

---

このとき、あるノードでは書き込みが失敗する可能性がある。そして別のクライアントが1つのノードから読み込みをするとき、その失敗したノードかもしれない。

この問題を解決するためには、クライアントがDBから**読み取る際にも複数のノードに並行に送信する**。

正しい最新値かを判別するにはバージョン番号が利用される。

---

#### 5.4.1.1 読み取り修復とエントロピー

書き込みに失敗したノードはどのように書き込みを取り戻すのか

* 読み取り修復
  * クライアント側が古い値を持つノードを見つけたら修復の書き込みをしてあげる。ただし読み取り頻度が少なければ放置される。
* 反エントロピー(Anti-Entropy)処理
  * バックグラウンドで修復する方法

---

#### 5.4.1.2 読み書きのためのクオラム(Quorum)

全部で`n`個のレプリカがあり、書き込みが少なくとも`w`個のノードで成功したとみなされ、読み込みの際は最低でも`r`個のノードでクエリを実行しないといけないとする。

このとき、 `w + r > n` である限りは少なくとも読み取り対象の`r`個の内、1つは最新のバージョンを持っていることを保証できる。

---

DynamoスタイルのDBでは、通常、パラメータの`n`,`w`,`r`は設定可能である。

-----

### 5.4.2 クオラムの一貫性の限界

`w + r > n` の場合でも、古い値が返されるようなエッジケース

* 2つの書き込み・読み込みが並行して行われる場合
* ノードにて障害が発生したとき

Dynamoスタイルでは結果整合性で耐えられるユースケースに最適化されている。

強い保証を得るためには、概してトランザクションや合意が必要になる。

-----
### 5.4.3 いい加減なクオラム

障害発生時、書き込み処理においてクオラムを満たすべき書き込みノードの一部が応答しないとき

* ① 必ずエラーにしてどのノードにも書き込ませない
* ② 書き込めるものは書き込んでしまう

②の方針のことをいい加減なクオラム(sloppy quoram)と呼ぶ。

-----

### 5.4.4 並行書き込みの検出

#### 5.4.4.1 最後の書き込みを勝たせる (並行した書き込みを捨てる)

Last Write Wins (LWW) と呼ばれる。

---

#### 5.4.4.2 事前発生 関係性と並行性

操作Bが操作Aについて"知っているとき"それは、操作Bは操作Aよりも**先に行われた**、と言える。

どちらも他方の操作を知らないのであれば、単純に2つの操作は**並行**している、と言える。

---

#### 5.4.4.3 事前発生関係の捕捉

todo: 図5-13