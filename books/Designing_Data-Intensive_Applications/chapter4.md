# Chapter 3

エンコーディングと進化

-----

新旧データフォーマットがシステム内で共存するときにスムーズに動作し続けるために互換性が必要。

* **後方互換性** From古いコード
  * 古いコードによって書かれたデータを新しいコードが読めること
* **前方互換性** From新しいコード
  * 新しいコードによって書かれたデータを古いコードが読めること

-----

## 4.1 データエンコードのフォーマット

<重要> データというものは以下の2つの異なる表現で扱われる。

1. メモリ内にてオブジェクト、リスト、配列、ツリーなどで保持される。これらのデータ構造はCPUによるアクセス操作が効率的になるようになっている。(通常はポインタ)

2. ファイルにデータを書いたり、ネットワーク経由でデータを送信する場合は、データは何らかのバイトの並びとしてエンコードされている必要がある。

-----

1.を2.にすることをエンコード(シリアライズ, マーシャル)と呼び、2.を1.にすることをデコード(パース, デシリアライズ, アンマーシャル)と呼ぶ。

-----

### 4.1.1 言語固有のフォーマット

ごく一時的な場合を除けば、特定の言語の組み込みをエンコードに使うのは良くない考えである。

-----

### 4.1.2 JSON, XML, 様々なバイナリフォーマット

JSONドキュメントをバイナリエンコードすると、その中のどこかにfield名の文字列を含める必要がある。

-----

### 4.1.3 ThriftとProtocol Buffers

ThriftとProtocol Buffersはどちらも同じ原理に基づくバイナリエンコーディングライブラリである。どちらもエンコードするためのデータに対するスキーマを必要とする。

---

Thriftの定義言語

```
struct Person {
    1: required string userName,
    2: optional i64 favoriteNumber,
    3: optional list<string> interests
}
```

---

TODO: pic1

---

Protocol Buffersの定義言語

```
message Person {
    required string user_name       = 1;
    optional int634 favorite_number = 2;
    repeated string interests       = 3;
}
```

---

TODO: pic2

---

#### 4.1.3.1 フィールドタグとスキーマの進化

**スキーマの進化 (schema evolution)** スキーマが時間の経過とともに変化せざるを得ない。

Thrift, Protocol Buffersにおいて、フィールドのタグ(1,2,3...)は変更できない。これはタグを変更するとエンコード済みの既存の全データが不正なものになるため。

新しいタグ番号を使う限りにおいて、スキーマには新しいフィールドを加えることできる。

---

#### 4.1.3.2 データ型とスキーマの進化

Protocol Buffersの細部で興味深いのは、リストや配列のデータを持たず、その代わりにフィールドに`repeated`マーカーがあること。これによって`optional`は0もしくは1のrepeatedとみなすことができ、相互に変換することを可能にしている。

-----

### 4.1.4 Avro

Apache Avroは、ThriftがHadoopのユースケースにうまく適合しなかったことを受けて、2009年にHadoopの副プロジェクトとして立ち上がった。

---

Avro IDL

```
record Person {
    string userName;
    union { null, long } favoriteNumber = null;
    array<string> interests;
}
```

---

TODO: pic3

---

**何よりもまず、このスキーマにはタグ番号がないことに注目してください**。 これはこれまでのエンコーディングの中では最もコンパクトです。 

Avroはどのようにスキーマの進化を扱うか。

---

#### 4.1.4.1 WriterのスキーマとReaderのスキーマ

Avroで、アプリケーションがデータをエンコードするときのスキーマをWriterのスキーマと呼び、アプリケーションがデータをデコードするときのスキーマをReaderのスキーマと呼ぶ。

Avroにおいて鍵となるのは、WriterのスキーマとReaderのスキーマは**同一である必要がなく**、互換性さえあれば良いという考え方。

---

データがデコードされる際にAvroのライブラリはこの差異をWriterのスキーマとReaderのスキーマを並べることよって解決し、WriterのスキーマからReaderのスキーマへデータを変換する。

---

#### 4.1.4.3 そもそもWriterのスキーマとは何なのか？

どうやって、WriterのスキーマをReaderが知るのか。

この疑問に対する答えはAvroの使われ方にあります。

---

**大量のレコードを持つ大きなファイルの場合**

Hadoopのユースケース。ファイルのWriterがファイルの先頭に一度だけWriterのスキーマを含めておくだけで済む。

---

**個別にレコードに書かれるデータベースの場合**

データベース内のエンコードされたレコードの先頭にスキーマのバージョン番号を含め、スキーマのバージョンのリストをデータベースに保存しておき、データベースからバージョン番号に応じたWriterのスキーマをフェッチする。

---

**ネットワーク経由でレコードを送信する場合**

2つのプロセスが双方向のネットワーク接続経由で通信している場合、それらのプロセスは接続の確立時にスキーマのバージョンのネゴシエーションを行い、接続が続く間そのスキーマを使う。

---

#### 4.1.4.4 動的に生成されたスキーマ

Avroの利点として、**動的に生成されたスキーマ**との相性が良いことにあります。

データベースのスキーマを変更するユースケースの際、ThriftやProtocol Buffersでやろうとした場合、フィールドタグの割当はおそらく手作業になる。

一方で、Avroであれば、現時点のDBスキーマからそのままAvroのスキーマを生成しアプリケーションに利用することができる。

-----

## 4.2 データフローの形態

-----


#### 4.2.3.2 分散アクターフレームワーク

* Akka
* Orleans
* Erlang OTP